<!DOCTYPE html>
<html>
<head>
  <script src="face-api.js"></script>
  <script src="FileSaver.js"></script>
  <script src="commons.js"></script>
  <script src="js/faceExpressionsCommons.js"></script>
  <script src="js/train.js"></script>
</head>
<body>
  <div id="container"></div>

  <script>
    tf = faceapi.tf

    // load the FaceLandmark68Net and use it's feature extractor since we only
    // train the output layer of the FaceExpressionNet
    const dummyLandmarkNet = new faceapi.FaceLandmark68Net()
    window.net = new faceapi.FaceExpressionNet(dummyLandmarkNet.faceFeatureExtractor)

    // uri to weights file of last checkpoint
    const modelCheckpoint = 'tmp/full/face_expression_model_120.weights'
    const startEpoch = 121

    const learningRate = 0.00001
    window.optimizer = tf.train.adam(learningRate, 0.9, 0.999, 1e-8)

    window.saveEveryNthSample = Infinity

    window.batchSize = 8
    //window.batchSize = 32

    window.lossValues = []

    window.iterDelay = 0
    window.withLogging = true

    async function load() {
      window.trainData = await faceapi.fetchJson('trainData.json')

      // fetch the actual output layer weights
      const weights = await faceapi.fetchNetWeights(modelCheckpoint)
      await window.net.load(weights)
      window.net.faceFeatureExtractor.variable()
      window.net.variable()
    }

  </script>
</body>
</html>