<!DOCTYPE html>
<html>
<head>
  <script src="face-api.js"></script>
  <script src="FileSaver.js"></script>
  <script src="commons.js"></script>
  <script src="js/faceExpressionsCommons.js"></script>
</head>
<body>
  <div id="container"></div>

  <script>
    tf = faceapi.tf

    // load the FaceLandmark68Net and use it's feature extractor since we only
    // train the output layer of the FaceExpressionNet
    const dummyLandmarkNet = new faceapi.FaceLandmark68Net()
    window.net = new faceapi.FaceExpressionNet(dummyLandmarkNet.faceFeatureExtractor)

    // uri to weights file of last checkpoint
    const modelCheckpoint = 'tmp/classifier/face_expression_model_121.weights'
    const startEpoch = 0

    const learningRate = 0.0001
    window.optimizer = tf.train.adam(learningRate, 0.9, 0.999, 1e-8)

    window.saveEveryNthSample = Infinity

    window.batchSize = 32
    //window.batchSize = 32

    window.lossValues = []

    window.iterDelay = 0
    window.withLogging = true

    async function load() {
      window.trainData = await faceapi.fetchJson('trainData.json')
      await dummyLandmarkNet.load('/')

      // fetch the actual output layer weights
      const classifierWeights = await faceapi.fetchNetWeights(modelCheckpoint)
      await window.net.loadClassifierParams(classifierWeights)
      window.net.variable()
    }

    async function train() {
      await load()

      for (let epoch = startEpoch; epoch < Infinity; epoch++) {

        if (epoch !== startEpoch) {
          // ugly hack to wait for loss datas for that epoch to be resolved
          setTimeout(() => onEpochDone(epoch - 1), 10000)
        }
        window.lossValues[epoch] = 0

        const shuffledInputs = prepareDataForEpoch(window.trainData)

        for (let dataIdx = 0; dataIdx < shuffledInputs.length; dataIdx += window.batchSize) {
          const tsIter = Date.now()

          const batchData = shuffledInputs.slice(dataIdx, dataIdx + window.batchSize)
          const bImages = await Promise.all(
            batchData
              .map(data => getImageUrl(data))
              .map(imgUrl => faceapi.fetchImage(imgUrl))
          )
          const bOneHotVectors = batchData
            .map(data => getLabelOneHotVector(data.label))

          let tsBackward = Date.now()
          let tsForward = Date.now()
          const bottleneckFeatures = await window.net.faceFeatureExtractor.forward(bImages)
          tsForward = Date.now() - tsForward

          const loss = optimizer.minimize(() => {
            tsBackward = Date.now()
            const labels = tf.tensor2d(bOneHotVectors)
            const out = window.net.runNet(bottleneckFeatures)

            const loss = tf.losses.softmaxCrossEntropy(
              labels,
              out,
              tf.Reduction.MEAN
            )

            return loss
          }, true)
          tsBackward = Date.now() - tsBackward

          bottleneckFeatures.dispose()

          // start next iteration without waiting for loss data

          loss.data().then(data => {
            const lossValue = data[0]
            window.lossValues[epoch] += lossValue
            window.withLogging && log(`epoch ${epoch}, dataIdx ${dataIdx} - loss: ${lossValue}, ( ${window.lossValues[epoch]})`)
            loss.dispose()
          })

          window.withLogging && log(`epoch ${epoch}, dataIdx ${dataIdx} - forward: ${tsForward} ms, backprop: ${tsBackward} ms, iter: ${Date.now() - tsIter} ms`)
          if (window.logsilly)  {
            log(`fetch: ${tsFetch} ms, pts: ${tsFetchPts} ms, jpgs: ${tsFetchJpgs} ms, bufferToImage: ${tsBufferToImage} ms`)
          }
          if (window.iterDelay) {
            await delay(window.iterDelay)
          } else {
            await tf.nextFrame()
          }
        }
      }
    }

  </script>
</body>
</html>