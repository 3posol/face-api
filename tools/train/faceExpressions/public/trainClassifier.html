<!DOCTYPE html>
<html>
<head>
  <script src="face-api.js"></script>
  <script src="FileSaver.js"></script>
  <script src="js/commons.js"></script>
</head>
<body>
  <div id="container"></div>

  <script>
    tf = faceapi.tf

    // load the FaceLandmark68Net and use it's feature extractor since we only
    // train the output layer of the FaceExpressionNet
    const dummyLandmarkNet = new faceapi.FaceLandmark68Net()
    window.net = new faceapi.FaceExpressionNet(dummyLandmarkNet.faceFeatureExtractor)

    // uri to weights file of last checkpoint
    const modelCheckpoint = 'tmp/face_expression_model_148.weights'
    const startEpoch = 149

    const learningRate = 0.001
    window.optimizer = tf.train.adam(learningRate, 0.9, 0.999, 1e-8)

    window.saveEveryNthSample = Infinity

    window.batchSize = 32
    //window.batchSize = 32

    window.lossValues = []

    window.iterDelay = 0
    window.withLogging = true

    const log = (str, ...args) => console.log(`[${[(new Date()).toTimeString().substr(0, 8)]}] ${str || ''}`, ...args)

    function saveWeights(net, filename = 'train_tmp') {
      saveAs(new Blob([net.serializeParams()]), filename)
    }

    async function delay(ms) {
      return new Promise(res => setTimeout(res, ms))
    }

    async function load() {
      window.trainData = await faceapi.fetchJson('trainData.json')
      await dummyLandmarkNet.load('/')

      // fetch the actual output layer weights
      const classifierWeights = await faceapi.fetchNetWeights(modelCheckpoint)
      await window.net.loadClassifierParams(classifierWeights)
      window.net.variable()
    }

    async function onEpochDone(epoch) {
      saveWeights(window.net, `face_expression_model_${epoch}.weights`)

      const loss = window.lossValues[epoch]
      saveAs(new Blob([JSON.stringify({ loss, avgLoss: loss / (2000 * 7) })]), `face_expression_model_${epoch}.json`)

    }

    function prepareDataForEpoch() {
      return faceapi.shuffleArray(
        Object.keys(window.trainData).map(label => {
          let dataForLabel = window.trainData[label].map(data => ({ ...data, label }))
          // since train data for "disgusted" have less than 2000 samples
          // use some data twice to ensure an even distribution
          dataForLabel = label === 'disgusted'
            ? faceapi.shuffleArray(dataForLabel.concat(dataForLabel).concat(dataForLabel)).slice(0, 2000)
            : dataForLabel
          return dataForLabel
        }).reduce((flat, arr) => arr.concat(flat))
      )
    }

    function getLabelOneHotVector(emotion) {
      const label = faceapi.FaceExpressionNet.getEmotionLabel(emotion)
      return Array(7).fill(0).map((_, i) => i === label ? 1 : 0)
    }

    async function train() {
      await load()

      for (let epoch = startEpoch; epoch < Infinity; epoch++) {

        if (epoch !== startEpoch) {
          // ugly hack to wait for loss datas for that epoch to be resolved
          setTimeout(() => onEpochDone(epoch - 1), 10000)
        }
        window.lossValues[epoch] = 0

        const shuffledInputs = prepareDataForEpoch()
          console.log(shuffledInputs)

        for (let dataIdx = 0; dataIdx < shuffledInputs.length; dataIdx += window.batchSize) {
          const tsIter = Date.now()

          const batchData = shuffledInputs.slice(dataIdx, dataIdx + window.batchSize)
          const bImages = await Promise.all(
            batchData
              .map(data => getImageUrl(data))
              .map(imgUrl => faceapi.fetchImage(imgUrl))
          )
          const bOneHotVectors = batchData
            .map(data => getLabelOneHotVector(data.label))

          let tsBackward = Date.now()
          let tsForward = Date.now()
          const bottleneckFeatures = await window.net.faceFeatureExtractor.forward(bImages)
          tsForward = Date.now() - tsForward

          const loss = optimizer.minimize(() => {
            tsBackward = Date.now()
            const labels = tf.tensor2d(bOneHotVectors)
            const out = window.net.forwardInput(bottleneckFeatures)

            const loss = tf.losses.softmaxCrossEntropy(
              labels,
              out,
              tf.Reduction.MEAN
            )

            return loss
          }, true)
          tsBackward = Date.now() - tsBackward

          bottleneckFeatures.dispose()

          // start next iteration without waiting for loss data

          loss.data().then(data => {
            const lossValue = data[0]
            window.lossValues[epoch] += lossValue
            window.withLogging && log(`epoch ${epoch}, dataIdx ${dataIdx} - loss: ${lossValue}, ( ${window.lossValues[epoch]})`)
            loss.dispose()
          })

          window.withLogging && log(`epoch ${epoch}, dataIdx ${dataIdx} - forward: ${tsForward} ms, backprop: ${tsBackward} ms, iter: ${Date.now() - tsIter} ms`)
          if (window.logsilly)  {
            log(`fetch: ${tsFetch} ms, pts: ${tsFetchPts} ms, jpgs: ${tsFetchJpgs} ms, bufferToImage: ${tsBufferToImage} ms`)
          }
          if (window.iterDelay) {
            await delay(window.iterDelay)
          } else {
            await tf.nextFrame()
          }
        }
      }
    }

  </script>
</body>
</html>