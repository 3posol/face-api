<!DOCTYPE html>
<html>
<head>
  <script src="face-api.js"></script>
  <script src="FileSaver.js"></script>
  <script src="js/commons.js"></script>
</head>
<body>
  <div id="container"></div>
  <div id="template" style="display: inline-flex; flex-direction: column;">
    <span class="emotion-text"></span>
    <span class="predicted-text"></span>
  </div>

  <script>
    tf = faceapi.tf

    // load the FaceLandmark68Net and use it's feature extractor since we only
    // train the output layer of the FaceExpressionNet
    const dummyLandmarkNet = new faceapi.FaceLandmark68Net()
    window.net = new faceapi.FaceExpressionNet(dummyLandmarkNet.faceFeatureExtractor)

    // uri to weights file of last checkpoint
    const modelCheckpoint = 'tmp/initial_classifier.weights'
    const startEpoch = 0

    const learningRate = 0.1 // 0.001
    window.optimizer = tf.train.adam(learningRate, 0.9, 0.999, 1e-8)

    window.batchSize = 32

    window.iterDelay = 0
    window.withLogging = true

    const log = (str, ...args) => console.log(`[${[(new Date()).toTimeString().substr(0, 8)]}] ${str || ''}`, ...args)

    async function load() {
      window.trainData = await faceapi.fetchJson('trainData.json')
      await dummyLandmarkNet.load('/')

      // fetch the actual output layer weights
      const classifierWeights = await faceapi.fetchNetWeights(modelCheckpoint)
      await window.net.loadClassifierParams(classifierWeights)
      window.net.variable()
    }

    function prepareDataForEpoch() {
      return faceapi.shuffleArray(
        Object.keys(window.trainData).map(label => {
          let dataForLabel = window.trainData[label].map(data => ({ ...data, label }))
          // since train data for "disgusted" have less than 2000 samples
          // use some data twice to ensure an even distribution
          dataForLabel = label === 'disgusted'
            ? faceapi.shuffleArray(dataForLabel.concat(dataForLabel).concat(dataForLabel)).slice(0, 2000)
            : dataForLabel
          return dataForLabel
        }).reduce((flat, arr) => arr.concat(flat))
      )
    }

    function getLabelOneHotVector(emotion) {
      const label = faceapi.FaceExpressionNet.getEmotionLabel(emotion)
      return Array(7).fill(0).map((_, i) => i === label ? 1 : 0)
    }

    async function train() {
      await load()

      const shuffledInputs = prepareDataForEpoch().slice(0, window.batchSize)
      const batchData = shuffledInputs
      const bImages = await Promise.all(
        batchData
          .map(data => getImageUrl(data))
          .map(imgUrl => faceapi.fetchImage(imgUrl))
      )
      const bOneHotVectors = batchData
        .map(data => getLabelOneHotVector(data.label))

      const container = document.getElementById('container')
      const template = document.getElementById('template')

      bImages.forEach((img, i) => {
        console.log(i, batchData[i].label, batchData[i].img)

        const squaredImg = faceapi.imageToSquare(img, 112, true)
        const emotions = faceapi.FaceExpressionNet
          .decodeEmotions(bOneHotVectors[i])
          .filter(e => e.probability > 0)

        const clone = template.cloneNode(true)
        clone.id = i
        const span = clone.firstElementChild
        span.innerHTML = i + ':' + emotions[0].label
        clone.insertBefore(squaredImg, span)
        container.appendChild(clone)
      })

      for (let epoch = startEpoch; epoch < Infinity; epoch++) {

        const bottleneckFeatures = await window.net.faceFeatureExtractor.forward(bImages)

        const loss = optimizer.minimize(() => {
          const labels = tf.tensor2d(bOneHotVectors)
          const out = window.net.forwardInput(bottleneckFeatures)

          const loss = tf.losses.softmaxCrossEntropy(
            labels,
            out,
            tf.Reduction.MEAN
          )

          const predictedByBatch = tf.unstack(out)
          predictedByBatch.forEach((p, i) => {
            const probabilities = Array.from(p.dataSync())
            const emotions = faceapi.FaceExpressionNet.decodeEmotions(probabilities)
            const container = document.getElementById(i)

            const pred = emotions.reduce((best, curr) => curr.probability > best.probability ? curr : best)

            const predNode = container.children[container.children.length - 1]

            predNode.innerHTML =
              pred.label + ' (' +  faceapi.round(pred.probability) + ')'
          })

          return loss
        }, true)

        bottleneckFeatures.dispose()

        // start next iteration without waiting for loss data

        loss.data().then(data => {
          const lossValue = data[0]
          log(`epoch ${epoch}, loss: ${lossValue}`)
          loss.dispose()
        })

        if (window.iterDelay) {
          await delay(window.iterDelay)
        } else {
          await tf.nextFrame()
        }
      }
    }

  </script>
</body>
</html>